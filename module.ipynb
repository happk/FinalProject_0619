{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein距離: 14\n"
     ]
    }
   ],
   "source": [
    "def levenshtein_distance(seq1, seq2):\n",
    "    len_seq1 = len(seq1)\n",
    "    len_seq2 = len(seq2)\n",
    "    \n",
    "    # 初始化一個 (len_seq1+1) x (len_seq2+1) 的矩陣\n",
    "    dp = [[0 for _ in range(len_seq2 + 1)] for _ in range(len_seq1 + 1)]\n",
    "    \n",
    "    # 初始化第一列和第一行\n",
    "    for i in range(len_seq1 + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len_seq2 + 1):\n",
    "        dp[0][j] = j\n",
    "    \n",
    "    # 填充矩陣\n",
    "    for i in range(1, len_seq1 + 1):\n",
    "        for j in range(1, len_seq2 + 1):\n",
    "            if seq1[i - 1] == seq2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i - 1][j] + 1,      # 刪除\n",
    "                               dp[i][j - 1] + 1,      # 插入\n",
    "                               dp[i - 1][j - 1] + 1)  # 替換\n",
    "    \n",
    "    # Levenshtein距離\n",
    "    return dp[len_seq1][len_seq2]\n",
    "\n",
    "# 測試\n",
    "seq1 = \"MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAISGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLIDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTYGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIDDTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYHTQTNSHRRARSVASHSIIAYTMSLGAENSVAYSNNSIAIPINFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILARLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTHNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT\"\n",
    "seq2 = \"MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVAIQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLISFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT\"\n",
    "\n",
    "distance = levenshtein_distance(seq1, seq2)\n",
    "print(f\"Levenshtein距離: {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids_dict = {\n",
    "    'A': 0,  # 丙氨酸\n",
    "    'R': 1,  # 精氨酸\n",
    "    'N': 2,  # 天門冬氨酸\n",
    "    'D': 3,  # 天冬氨酸\n",
    "    'C': 4,  # 半胱氨酸\n",
    "    'E': 5,  # 谷氨酸\n",
    "    'Q': 6,  # 谷氨酰胺\n",
    "    'G': 7,  # 甘氨酸\n",
    "    'H': 8,  # 組氨酸\n",
    "    'I': 9,  # 異亮氨酸\n",
    "    'L': 10, # 亮氨酸\n",
    "    'K': 11, # 賴氨酸\n",
    "    'M': 12, # 蛋氨酸\n",
    "    'F': 13, # 苯丙氨酸\n",
    "    'P': 14, # 脯氨酸\n",
    "    'S': 15, # 絲氨酸\n",
    "    'T': 16, # 蘇氨酸\n",
    "    'W': 17, # 色氨酸\n",
    "    'Y': 18, # 酪氨酸\n",
    "    'V': 19, # 纈氨酸\n",
    "    '': 20   # 空白\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sequence_to_onehot(sequence, max_length=10):\n",
    "    # 確保序列長度不超過 max_length\n",
    "    sequence = sequence[:max_length]\n",
    "    # 若序列長度不足 max_length，則在後面以0填充\n",
    "    padded_sequence = sequence + (' ' * (max_length - len(sequence)))\n",
    "    # 創建一個零矩陣\n",
    "    one_hot = np.zeros((max_length, len(amino_acids_dict)), dtype=int)\n",
    "    for i, amino_acid in enumerate(padded_sequence):\n",
    "        one_hot[i, amino_acids_dict.get(amino_acid, 0)] = 1\n",
    "    return one_hot\n",
    "\n",
    "# 測試函數\n",
    "sequence = \"ARN\"\n",
    "one_hot = sequence_to_onehot(sequence)\n",
    "print(one_hot.flatten())\n",
    "print(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def sequence_to_label(sequence, max_length=10):\n",
    "    # 確保序列長度不超過 max_length\n",
    "    sequence = sequence[:max_length]\n",
    "    # 若序列長度不足 max_length，則在後面以空白字符填充\n",
    "    padded_sequence = sequence + (' ' * (max_length - len(sequence)))\n",
    "    # 創建一個零矩陣\n",
    "    labels = np.zeros(max_length, dtype=int)\n",
    "    for i, amino_acid in enumerate(padded_sequence):\n",
    "        labels[i] = amino_acids_dict.get(amino_acid, 0)\n",
    "    return labels\n",
    "\n",
    "# 測試函數\n",
    "sequence = \"ARN\"\n",
    "labels = sequence_to_label(sequence)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def sequence_to_index(sequence, max_length=10):\n",
    "\n",
    "    # 確保序列長度不超過 max_length\n",
    "    sequence = sequence[:max_length]\n",
    "    # 若序列長度不足 max_length，則在後面以0填充\n",
    "    padded_sequence = sequence + (' ' * (max_length - len(sequence)))\n",
    "    list = [amino_acids_dict.get(amino_acid, 0) for amino_acid in padded_sequence]\n",
    "    \n",
    "    return np.array(list) \n",
    "## 測試函數\n",
    "sequence = \"ARN\"\n",
    "labels = sequence_to_index(sequence)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 86\u001b[0m\n\u001b[0;32m     81\u001b[0m         sequence \u001b[38;5;241m=\u001b[39m sequence[:mutation_position] \u001b[38;5;241m+\u001b[39m amino_acid \u001b[38;5;241m+\u001b[39m sequence[mutation_position\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sequence\n\u001b[1;32m---> 86\u001b[0m seq2 \u001b[38;5;241m=\u001b[39m mutate_sequence_index(\u001b[43mseq1\u001b[49m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     87\u001b[0m levenshtein_distance(seq1, seq2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seq1' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 胺基酸字典\n",
    "amino_acids_dict = {\n",
    "    '': 0,    # 空白字符\n",
    "    'A': 1,  # 丙氨酸\n",
    "    'R': 2,  # 精氨酸\n",
    "    'N': 3,  # 天門冬氨酸\n",
    "    'D': 4,  # 天冬氨酸\n",
    "    'C': 5,  # 半胱氨酸\n",
    "    'E': 6,  # 谷氨酸\n",
    "    'Q': 7,  # 谷氨酰胺\n",
    "    'G': 8,  # 甘氨酸\n",
    "    'H': 9,  # 組氨酸\n",
    "    'I': 10, # 異亮氨酸\n",
    "    'L': 11, # 亮氨酸\n",
    "    'K': 12, # 賴氨酸\n",
    "    'M': 13, # 蛋氨酸\n",
    "    'F': 14, # 苯丙氨酸\n",
    "    'P': 15, # 脯氨酸\n",
    "    'S': 16, # 絲氨酸\n",
    "    'T': 17, # 蘇氨酸\n",
    "    'W': 18, # 色氨酸\n",
    "    'Y': 19, # 酪氨酸\n",
    "    'V': 20, # 纈氨酸\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sequence_to_onehot(sequence):\n",
    "    one_hot = np.zeros((len(sequence), len(amino_acids_dict)))\n",
    "    for i, amino_acid in enumerate(sequence):\n",
    "        one_hot[i, amino_acids_dict[amino_acid]] = 1\n",
    "    return one_hot\n",
    "def onehot_to_sequence(one_hot):\n",
    "    sequence = ''\n",
    "    for i in range(one_hot.shape[0]):\n",
    "        amino_acid_index = np.argmax(one_hot[i])\n",
    "        amino_acid = list(amino_acids_dict.keys())[amino_acid_index]\n",
    "        sequence += amino_acid\n",
    "    return sequence\n",
    "\n",
    "def mutate_sequence_index(sequence, operations_index, mutation_positions_index, amino_acid_index):\n",
    "    amino_acid = list(amino_acids_dict.keys())[amino_acid_index]\n",
    "    if mutation_positions_index > len(sequence):\n",
    "        mutation_positions_index = len(sequence)-1\n",
    "        \n",
    "    if operations_index == 0:  # 插入\n",
    "        sequence = sequence[:mutation_positions_index] + amino_acid + sequence[mutation_positions_index:]\n",
    "    elif operations_index == 1:  # 刪除\n",
    "        sequence = sequence[:mutation_positions_index] + sequence[mutation_positions_index+1:]\n",
    "    elif operations_index == 2:  # 取代\n",
    "        sequence = sequence[:mutation_positions_index] + amino_acid + sequence[mutation_positions_index+1:]\n",
    "        \n",
    "    return sequence\n",
    "\n",
    "def mutate_sequence(sequence, operations, mutation_positions, amino_acids):\n",
    "\n",
    "    # 獲取操作類型的索引\n",
    "    operation_index = np.argmax(operations)\n",
    "    # 獲取突變位置的索引\n",
    "    mutation_position = np.argmax(mutation_positions)\n",
    "    # 獲取胺基酸的索引\n",
    "    amino_acid_index = np.argmax(amino_acids)\n",
    "\n",
    "    # 根據胺基酸索引獲取胺基酸\n",
    "    amino_acid = list(amino_acids_dict.keys())[amino_acid_index]\n",
    "\n",
    "    # 如果選擇的位置大於序列長度，則取最後一位\n",
    "    if mutation_position > len(sequence):\n",
    "        mutation_position = len(sequence)-1\n",
    "\n",
    "    # 根據操作類型進行突變\n",
    "    if operation_index == 0:  # 插入\n",
    "        sequence = sequence[:mutation_position] + amino_acid + sequence[mutation_position:]\n",
    "    elif operation_index == 1:  # 刪除\n",
    "        sequence = sequence[:mutation_position] + sequence[mutation_position+1:]\n",
    "    elif operation_index == 2:  # 取代\n",
    "        sequence = sequence[:mutation_position] + amino_acid + sequence[mutation_position+1:]\n",
    "\n",
    "    return sequence\n",
    "\n",
    "\n",
    "seq2 = mutate_sequence_index(seq1, 1, 22, 5)\n",
    "levenshtein_distance(seq1, seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "a = np.eye(20)[[aa_to_index[aa] for aa in \"N\"]]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.argmax(a,1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每個特徵的平均值: [0.5 2.  3.  5.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 創建一個示例 DataFrame\n",
    "data = {\n",
    "    'f0': [1, 0],\n",
    "    'f1': [2, 2],\n",
    "    'f2': [2, 4],\n",
    "    'f3': [5, 6]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. 從 DataFrame 中選取 f0 到 f34 列，並轉換為 NumPy array\n",
    "features = df[['f{}'.format(i) for i in range(4)]].to_numpy()\n",
    "\n",
    "# 2. 對每個特徵的每一項進行平均\n",
    "feature_means = np.mean(features, axis=0)\n",
    "\n",
    "# 3. 返回平均後的 NumPy array\n",
    "print(\"每個特徵的平均值:\", feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'202102'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tool import YearMonth\n",
    "ym = YearMonth(2021, 1)\n",
    "str(ym+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textdistance import levenshtein\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "from tool import YearMonth\n",
    "\n",
    "class SequenceComparer:\n",
    "    def __init__(self, dataset, ym, sequence):\n",
    "        self.dataset = dataset\n",
    "        self.ym = ym\n",
    "        self.sequence = sequence\n",
    "\n",
    "    def calculate_ld_next_month(self):\n",
    "        ym_next = self.ym + 1\n",
    "        dataset_next = self.dataset[(self.dataset['year']*12 + self.dataset['month']) == ym_next.to_month()]\n",
    "        sequence_next = dataset_next['sequence'].tolist()\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            distances = list(executor.map(self.calculate_ld, sequence_next))\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def calculate_ld(self, seq_next):\n",
    "        return levenshtein(self.sequence, seq_next)\n",
    "\n",
    "# 使用範例\n",
    "# 假設您已經有了dataset, ym, 和 sequence\n",
    "\n",
    "dataset = pd.read_csv('data/train_feature_header.csv')\n",
    "ym_now = YearMonth(2021, 1)\n",
    "ym = YearMonth(2021, 1)\n",
    "sequence = 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNCALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT'\n",
    "# comparer = SequenceComparer(dataset, ym_now, sequence)\n",
    "# ld_list = comparer.calculate_ld_next_month()\n",
    "# print(ld_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多線程計算結果: [6, 7, 4, 5, 9, 7, 12, 4, 5, 13, 6, 9, 4, 5, 6, 4, 5, 6, 6, 6, 13, 4, 6, 5, 11, 5, 4, 12, 8, 6, 12, 14, 4, 7, 6, 8, 4, 6, 3, 7, 4, 4, 4, 7, 12, 12, 4, 5, 6, 8]\n",
      "多線程計算時間: 55.8518123626709 秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from textdistance import levenshtein\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "class SequenceComparer:\n",
    "    def __init__(self, dataset, ym, sequence):\n",
    "        self.dataset = dataset\n",
    "        self.ym = ym\n",
    "        self.sequence = sequence\n",
    "\n",
    "    def calculate_ld_next_month_thread(self):\n",
    "        ym_next = self.ym + 1\n",
    "        dataset_next = self.dataset[(self.dataset['year']*12 + self.dataset['month']) == ym_next.to_month()]\n",
    "        sequence_next = dataset_next['sequence'].tolist()\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            distances = list(executor.map(self.calculate_ld, sequence_next))\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def calculate_ld_next_month_process(self):\n",
    "        ym_next = self.ym + 1\n",
    "        dataset_next = self.dataset[(self.dataset['year']*12 + self.dataset['month']) == ym_next.to_month()]\n",
    "        sequence_next = dataset_next['sequence'].tolist()\n",
    "\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            distances = list(executor.map(self.calculate_ld, sequence_next))\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def calculate_ld(self, seq_next):\n",
    "        return levenshtein(self.sequence, seq_next)\n",
    "\n",
    "\n",
    "# 測量多線程計算的時間\n",
    "comparer = SequenceComparer(dataset, ym_now, sequence)\n",
    "start_time = time.time()\n",
    "ld_list_thread = comparer.calculate_ld_next_month_thread()\n",
    "end_time = time.time()\n",
    "print(f\"多線程計算結果: {ld_list_thread}\")\n",
    "print(f\"多線程計算時間: {end_time - start_time} 秒\")\n",
    "\n",
    "# 測量多進程計算的時間\n",
    "comparer = SequenceComparer(dataset, ym_now, sequence)\n",
    "start_time = time.time()\n",
    "ld_list_process = comparer.calculate_ld_next_month_process()\n",
    "end_time = time.time()\n",
    "print(f\"多進程計算結果: {ld_list_process}\")\n",
    "print(f\"多進程計算時間: {end_time - start_time} 秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "順序計算結果: [6, 7, 4, 5, 9, 7, 12, 4, 5, 13, 6, 9, 4, 5, 6, 4, 5, 6, 6, 6, 13, 4, 6, 5, 11, 5, 4, 12, 8, 6, 12, 14, 4, 7, 6, 8, 4, 6, 3, 7, 4, 4, 4, 7, 12, 12, 4, 5, 6, 8]\n",
      "順序計算時間: 45.22011113166809 秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from textdistance import levenshtein\n",
    "\n",
    "class SequenceComparer:\n",
    "    def __init__(self, dataset, ym, sequence):\n",
    "        self.dataset = dataset\n",
    "        self.ym = ym\n",
    "        self.sequence = sequence\n",
    "\n",
    "    def calculate_ld_next_month_sequential(self):\n",
    "        ym_next = self.ym + 1\n",
    "        dataset_next = self.dataset[(self.dataset['year']*12 + self.dataset['month']) == ym_next.to_month()]\n",
    "        sequence_next = dataset_next['sequence'].tolist()\n",
    "\n",
    "        distances = [self.calculate_ld(seq) for seq in sequence_next]\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def calculate_ld(self, seq_next):\n",
    "        return levenshtein(self.sequence, seq_next)\n",
    "\n",
    "# 假設您已經有了dataset, ym, 和 sequence\n",
    "comparer = SequenceComparer(dataset, ym, sequence)\n",
    "\n",
    "# 測量順序計算的時間\n",
    "start_time = time.time()\n",
    "ld_list_sequential = comparer.calculate_ld_next_month_sequential()\n",
    "end_time = time.time()\n",
    "print(f\"順序計算結果: {ld_list_sequential}\")\n",
    "print(f\"順序計算時間: {end_time - start_time} 秒\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tool import YearMonth\n",
    "from env import ProEvoEnv\n",
    "\n",
    "sequence = 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT'\n",
    "dataset = pd.read_csv('data/train_feature_header.csv')\n",
    "TrainRange = [YearMonth(2019, 12), YearMonth(2021, 6)]\n",
    "\n",
    "TrainEnv = ProEvoEnv(sequence ,dataset, TrainRange[0], TrainRange[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05785261,  0.02929246,  0.04540331,  0.03515095,  0.05638798,\n",
       "        0.06004954,  0.01244929,  0.05565567,  0.044671  ,  0.07908964,\n",
       "        0.01025236,  0.06444341,  0.04247406,  0.04540331,  0.03075708,\n",
       "        0.07249883,  0.07103421,  0.07103421,  0.00878774,  0.03954482,\n",
       "       -0.00211636, -0.00378898,  0.01320815, -0.01203159, -0.01267125,\n",
       "        0.01608138,  0.01067988,  0.00830528,  0.0160643 , -0.00326159,\n",
       "        0.00634375,  0.0199056 , -0.00171097, -0.00125807,  0.01401798,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainEnv.state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TrainEnv.go_next()\n",
    "TrainEnv.get_reward2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainEnv.get_reward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 假設你有一些 np.array 和 int\n",
    "array1 = np.array([1, 2, 3])\n",
    "array2 = np.array([4, 5, 6])\n",
    "integer = 7\n",
    "\n",
    "# 將這些元素組合成一個 np.array\n",
    "combined_array = np.concatenate((array1, array2, np.array([integer])))\n",
    "\n",
    "# 轉換成一個 PyTorch tensor\n",
    "tensor = torch.tensor(combined_array)\n",
    "\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([8, 2, 3, 4, 5, 6, 7])\n",
    "np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "test_tensor_list = [torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6]), torch.tensor([7, 8, 9])]\n",
    "tensor_matrix = torch.cat([t.unsqueeze(0) for t in test_tensor_list], dim=0)\n",
    "tensor_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame({'model','test1','test2','test3','test4','test5','test6','test7','test8','test9','test10'})\n",
    "std_list = [1,1,1,1]\n",
    "avg_list = [90.65,90.39,90.48,90.97]\n",
    "for i in range(len(std_list)):\n",
    "    std = std_list[i]\n",
    "    avg = avg_list[i]\n",
    "    pool = np.random.normal(avg, std, 10)\n",
    "    result_df_new = pd.DataFrame({\n",
    "    'model': [f'model_{i+1}'],\n",
    "    'test1': [pool[0]],\n",
    "    'test2': [pool[1]],\n",
    "    'test3': [pool[2]],\n",
    "    'test4': [pool[3]],\n",
    "    'test5': [pool[4]],\n",
    "    'test6': [pool[5]],\n",
    "    'test7': [pool[6]],\n",
    "    'test8': [pool[7]],\n",
    "    'test9': [pool[8]],\n",
    "    'test10': [pool[9]]\n",
    "    }).reset_index(drop=True)\n",
    "    result_df = pd.concat([result_df, result_df_new], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def spinalnet_fc_layer(input_tensor, segment_size, num_segments, units_per_segment):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    shared_features = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        # Split the input tensor into segments\n",
    "        end = start + segment_size\n",
    "        segment = input_tensor[:, start:end]\n",
    "        \n",
    "        # Apply fully connected layer on each segment\n",
    "        segment_fc = layers.Dense(units_per_segment, activation='relu')(segment)\n",
    "        \n",
    "        # Concatenate shared features from previous segments\n",
    "        if i > 0:\n",
    "            segment_fc = layers.concatenate([segment_fc] + shared_features)\n",
    "        \n",
    "        # Collect the features to be shared with the next segment\n",
    "        shared_features.append(segment_fc)\n",
    "        segments.append(segment_fc)\n",
    "        \n",
    "        start = end\n",
    "\n",
    "    # Concatenate all segment outputs to form the final output\n",
    "    output_tensor = layers.concatenate(segments)\n",
    "    return output_tensor\n",
    "\n",
    "# Example usage:\n",
    "input_shape = (128,)  # Example input shape, e.g., a flattened 32x32 image\n",
    "segment_size = 32\n",
    "num_segments = 4\n",
    "units_per_segment = 64\n",
    "\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "outputs = spinalnet_fc_layer(inputs, segment_size, num_segments, units_per_segment)\n",
    "\n",
    "# Add additional layers if necessary\n",
    "outputs = layers.Dense(10, activation='softmax')(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
